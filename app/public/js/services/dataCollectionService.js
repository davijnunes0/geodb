/**
 * Servi√ßo para coleta paralela de dados usando Web Workers
 * Gerencia m√∫ltiplos workers que buscam p√°ginas diferentes da API
 * Usa SharedArrayBuffer para mem√≥ria compartilhada com sincroniza√ß√£o Atomics
 * 
 * @see https://developer.mozilla.org/en-US/docs/Web/API/Web_Workers_API
 * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/SharedArrayBuffer
 * @see https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Atomics
 * 
 * Vers√£o: 1.1.0 - Corrigido erro totalCollected n√£o definido
 */

import { estimateBufferSize, serializeCity, deserializeCities } from "../util/sharedMemorySerializer.js";

/**
 * Verifica se SharedArrayBuffer est√° dispon√≠vel
 * Requer headers de seguran√ßa espec√≠ficos (Cross-Origin-Opener-Policy e Cross-Origin-Embedder-Policy)
 * @returns {boolean} True se dispon√≠vel
 */
const isSharedArrayBufferAvailable = () => {
  return typeof SharedArrayBuffer !== "undefined";
};

/**
 * Coleta dados de forma paralela usando Web Workers e mem√≥ria compartilhada
 * Implementa algoritmo de divis√£o e conquista com escrita controlada via Atomics
 * @param {number} targetCities - N√∫mero aproximado de cidades a coletar (~10000)
 * @param {number} limitPerPage - Limite de resultados por p√°gina
 * @param {Function} onProgress - Callback de progresso (progress, stats)
 * @returns {Promise<Array>} Array de cidades coletadas
 */
export const collectCitiesParallel = async (targetCities = 10000, limitPerPage = 10, onProgress) => {
  // Verifica disponibilidade de SharedArrayBuffer
  const useSharedMemory = isSharedArrayBufferAvailable();
  
  if (!useSharedMemory) {
    console.warn("SharedArrayBuffer n√£o dispon√≠vel. Usando fallback com postMessage.");
    return collectCitiesParallelFallback(targetCities, limitPerPage, onProgress);
  }

  // Calcula n√∫mero de p√°ginas necess√°rias
  const totalPages = Math.ceil(targetCities / limitPerPage);
  
  // N√∫mero de workers: ajustado para plano BASIC da RapidAPI
  // Plano BASIC tem limite muito restritivo (1 req/s)
  // Para garantir que n√£o excedemos o limite, usamos apenas 1 worker
  // Em planos superiores, pode-se aumentar este n√∫mero
  const numWorkers = 1; // Apenas 1 worker para respeitar limite do plano BASIC (1 req/s)
  
  // NOTA: Para demonstrar paralelismo real, em produ√ß√£o com plano superior,
  // pode-se usar: Math.min(Math.max(1, Math.floor(navigator.hardwareConcurrency || 4) / 2), 4)
  
  // Distribui p√°ginas entre workers (divis√£o e conquista)
  const pagesPerWorker = Math.ceil(totalPages / numWorkers);
  
  // Cria SharedArrayBuffer para mem√≥ria compartilhada
  // Estrutura: 
  // - 4 bytes: √≠ndice at√¥mico de escrita (Uint32)
  // - 4 bytes: contador de workers completos (Uint32)
  // - Resto: dados das cidades serializadas
  const headerSize = 8; // 2 Uint32 (writeIndex + completedWorkers)
  const estimatedDataSize = estimateBufferSize(targetCities * 1.5); // 50% de margem
  const totalBufferSize = headerSize + estimatedDataSize;
  
  let sharedBuffer;
  try {
    sharedBuffer = new SharedArrayBuffer(totalBufferSize);
  } catch (error) {
    console.warn("Erro ao criar SharedArrayBuffer:", error);
    return collectCitiesParallelFallback(targetCities, limitPerPage, onProgress);
  }

  // Inicializa √≠ndices at√¥micos no buffer compartilhado
  const atomicView = new Int32Array(sharedBuffer, 0, 2);
  Atomics.store(atomicView, 0, headerSize); // writeIndex come√ßa ap√≥s header
  Atomics.store(atomicView, 1, 0); // completedWorkers come√ßa em 0

  const workers = [];
  let totalProcessed = 0;
  
  // Vari√°veis para controle da Promise
  let resolvePromise = null;
  let rejectPromise = null;

  // Cria e inicializa workers com delay escalonado para rate limiting
  // Cada worker inicia com delay progressivo para distribuir requisi√ß√µes
  for (let i = 0; i < numWorkers; i++) {
    const startPage = i * pagesPerWorker + 1;
    const endPage = Math.min((i + 1) * pagesPerWorker, totalPages);

    // Se n√£o h√° p√°ginas para este worker, pula
    if (startPage > totalPages) {
      break;
    }

    // Delay escalonado n√£o necess√°rio com apenas 1 worker
    // Com m√∫ltiplos workers, cada um esperaria antes de iniciar para distribuir requisi√ß√µes
    // Worker 0: inicia imediatamente
    // Worker 1: esperaria 2.5s (se houvesse m√∫ltiplos workers)
    // Worker 2: esperaria 5s (se houvesse m√∫ltiplos workers)
    // etc.
    // Com apenas 1 worker (plano BASIC), n√£o h√° necessidade de delay escalonado

    const worker = new Worker("/js/workers/dataCollectionWorker.js", { type: "module" });

    // Passa SharedArrayBuffer e informa√ß√µes de sincroniza√ß√£o
    worker.postMessage({
      type: "start_collection",
      startPage,
      endPage,
      limit: limitPerPage,
      workerId: i,
      sharedBuffer: sharedBuffer, // SharedArrayBuffer √© transfer√≠vel
      headerSize: headerSize,
      totalBufferSize: totalBufferSize,
    });

    // Escuta mensagens do worker
    worker.onmessage = (event) => {
      const { type, workerId, page, citiesCollected, totalCitiesInPage, error, waitTime } = event.data;

      switch (type) {
        case "progress":
          totalProcessed++;
          // L√™ contador atual de cidades do buffer compartilhado
          let estimatedCollectedProgress = 0;
          try {
            if (atomicView && typeof Atomics !== 'undefined') {
              const currentWriteIndex = Atomics.load(atomicView, 0);
              estimatedCollectedProgress = Math.floor((currentWriteIndex - headerSize) / 200); // Estimativa baseada em tamanho m√©dio
            }
          } catch (e) {
            // Se n√£o conseguir ler do buffer compartilhado, usa 0
            console.warn("Erro ao estimar cidades coletadas no progress:", e);
          }
          
          if (onProgress) {
            const progress = Math.round((totalProcessed / totalPages) * 100);
            onProgress(progress, {
              workers: numWorkers,
              currentPage: page,
              totalPages,
              citiesCollected: estimatedCollectedProgress,
              workerId,
            });
          }
          break;

        case "progress_log":
          // Log de progresso do worker
          console.log(`[Worker ${event.data.workerId}] ${event.data.message}`);
          break;

        case "complete":
          // Incrementa contador at√¥mico de workers completos
          Atomics.add(atomicView, 1, 1);

          // Termina worker
          worker.terminate();
          break;

        case "rate_limit":
          // Rate limit atingido - informa usu√°rio
          if (onProgress) {
            const progress = Math.round((totalProcessed / totalPages) * 100);
            // Estima cidades coletadas baseado no √≠ndice de escrita atual
            let estimatedCollectedRateLimit = 0;
            try {
              if (atomicView && typeof Atomics !== 'undefined') {
                const currentWriteIndex = Atomics.load(atomicView, 0);
                estimatedCollectedRateLimit = Math.floor((currentWriteIndex - headerSize) / 200); // Estimativa baseada em tamanho m√©dio
              }
            } catch (e) {
              // Se n√£o conseguir ler do buffer compartilhado, usa 0
              console.warn("Erro ao estimar cidades coletadas:", e);
            }
            onProgress(progress, {
              workers: numWorkers,
              currentPage: page,
              totalPages,
              citiesCollected: estimatedCollectedRateLimit,
              workerId,
              rateLimit: true,
              waitTime,
            });
          }
          console.warn(`Worker ${workerId} rate limit na p√°gina ${page}. Aguardando ${waitTime}s...`);
          break;

        case "error":
          console.warn(`Worker ${workerId} erro na p√°gina ${page}:`, error);
          // N√£o incrementa completedWorkers aqui - worker continua tentando outras p√°ginas
          break;

        case "critical_error":
          console.error(`Worker ${workerId} erro cr√≠tico:`, error);
          worker.terminate();
          // Incrementa contador at√¥mico de workers completos mesmo em caso de erro cr√≠tico
          Atomics.add(atomicView, 1, 1);
          // Continua processamento mesmo se um worker falhar completamente
          break;

        default:
          console.warn(`Worker ${workerId} mensagem desconhecida:`, type);
      }
    };

    worker.onerror = (error) => {
      console.error(`Worker ${i} erro:`, error);
      worker.terminate();
      // Incrementa contador de workers completos mesmo em caso de erro
      Atomics.add(atomicView, 1, 1);
    };

    workers.push(worker);
  }

  // Aguarda todos os workers terminarem e l√™ dados do buffer compartilhado
  return new Promise((resolve, reject) => {
    resolvePromise = resolve;
    rejectPromise = reject;
    
    const checkComplete = setInterval(() => {
      const currentCompleted = Atomics.load(atomicView, 1);
      if (currentCompleted === numWorkers) {
        clearInterval(checkComplete);
        
        // L√™ dados do buffer compartilhado
        const finalWriteIndex = Atomics.load(atomicView, 0);
        const dataBuffer = sharedBuffer.slice(headerSize, finalWriteIndex);
        const allCities = deserializeCities(dataBuffer);
        
        // Remove duplicatas usando estrat√©gia multi-crit√©rio:
        // 1. Primeiro por ID (mais confi√°vel)
        // 2. Depois por nome + coordenadas pr√≥ximas (toler√¢ncia de 0.01 graus ‚âà 1km)
        const uniqueCitiesById = Array.from(
          new Map(allCities.map((city) => [city.id, city])).values()
        );
        
        // Remove duplicatas por nome + coordenadas pr√≥ximas
        const uniqueCities = [];
        const seen = new Map(); // key: "nome|lat|lon" (arredondado)
        
        for (const city of uniqueCitiesById) {
          const name = (city.name || city.cityName || "").toLowerCase().trim();
          // Arredonda coordenadas para detectar cidades muito pr√≥ximas
          const latRounded = Math.round(city.latitude * 100) / 100; // ~1km precis√£o
          const lonRounded = Math.round(city.longitude * 100) / 100;
          const key = `${name}|${latRounded}|${lonRounded}`;
          
          if (!seen.has(key)) {
            seen.set(key, city);
            uniqueCities.push(city);
          } else {
            // Se j√° existe, mant√©m a que tem maior popula√ß√£o (mais atualizada)
            const existing = seen.get(key);
            if (city.population > (existing.population || 0)) {
              const index = uniqueCities.indexOf(existing);
              if (index !== -1) {
                uniqueCities[index] = city;
                seen.set(key, city);
              }
            }
          }
        }
        
        console.log(`üîç Duplicatas removidas: ${allCities.length} ‚Üí ${uniqueCitiesById.length} (por ID) ‚Üí ${uniqueCities.length} (por nome+coord)`);

        // Atualiza progresso final
        if (onProgress) {
          onProgress(100, {
            workers: numWorkers,
            totalPages,
            citiesCollected: uniqueCities.length,
            completed: true,
          });
        }

        resolve(uniqueCities);
      }
    }, 100);

    // Timeout de seguran√ßa (10 minutos)
    setTimeout(() => {
      clearInterval(checkComplete);
      workers.forEach((worker) => worker.terminate());
      reject(new Error("Timeout na coleta de dados"));
    }, 600000);
  });
};

/**
 * Fallback: coleta sem SharedArrayBuffer (usa postMessage)
 * Mantido para compatibilidade com navegadores que n√£o suportam SharedArrayBuffer
 */
const collectCitiesParallelFallback = async (targetCities = 10000, limitPerPage = 10, onProgress) => {
  const totalPages = Math.ceil(targetCities / limitPerPage);
  const numWorkers = 1; // Fallback usa apenas 1 worker
  const pagesPerWorker = Math.ceil(totalPages / numWorkers);
  
  const workers = [];
  const allCities = [];
  let completedWorkers = 0;
  let totalCollected = 0;
  let totalProcessed = 0;

  for (let i = 0; i < numWorkers; i++) {
    const startPage = i * pagesPerWorker + 1;
    const endPage = Math.min((i + 1) * pagesPerWorker, totalPages);

    if (startPage > totalPages) break;

    const worker = new Worker("/js/workers/dataCollectionWorker.js", { type: "module" });

    worker.postMessage({
      type: "start_collection",
      startPage,
      endPage,
      limit: limitPerPage,
      workerId: i,
      useSharedMemory: false,
    });

    worker.onmessage = (event) => {
      const { type, cities, workerId, page, citiesCollected } = event.data;

      switch (type) {
        case "progress":
          totalProcessed++;
          if (onProgress) {
            const progress = Math.round((totalProcessed / totalPages) * 100);
            onProgress(progress, {
              workers: numWorkers,
              currentPage: page,
              totalPages,
              citiesCollected: totalCollected + (citiesCollected || 0),
              workerId,
            });
          }
          break;

        case "complete":
          completedWorkers++;
          allCities.push(...(cities || []));
          totalCollected += (cities || []).length;
          worker.terminate();
          if (completedWorkers === workers.length) {
            if (onProgress) {
              onProgress(100, {
                workers: numWorkers,
                totalPages,
                citiesCollected: totalCollected,
                completed: true,
              });
            }
          }
          break;

        case "error":
          console.warn(`Worker ${workerId} erro na p√°gina ${page}:`, event.data.error);
          break;

        case "critical_error":
          console.error(`Worker ${workerId} erro cr√≠tico:`, event.data.error);
          worker.terminate();
          completedWorkers++;
          break;
      }
    };

    worker.onerror = (error) => {
      console.error(`Worker ${i} erro:`, error);
      worker.terminate();
      completedWorkers++;
    };

    workers.push(worker);
  }

  return new Promise((resolve, reject) => {
    const checkComplete = setInterval(() => {
      if (completedWorkers === workers.length) {
        clearInterval(checkComplete);
        
        // Remove duplicatas usando estrat√©gia multi-crit√©rio (mesma l√≥gica do SharedArrayBuffer)
        const uniqueCitiesById = Array.from(
          new Map(allCities.map((city) => [city.id, city])).values()
        );
        
        const uniqueCities = [];
        const seen = new Map();
        
        for (const city of uniqueCitiesById) {
          const name = (city.name || city.cityName || "").toLowerCase().trim();
          const latRounded = Math.round(city.latitude * 100) / 100;
          const lonRounded = Math.round(city.longitude * 100) / 100;
          const key = `${name}|${latRounded}|${lonRounded}`;
          
          if (!seen.has(key)) {
            seen.set(key, city);
            uniqueCities.push(city);
          } else {
            const existing = seen.get(key);
            if (city.population > (existing.population || 0)) {
              const index = uniqueCities.indexOf(existing);
              if (index !== -1) {
                uniqueCities[index] = city;
                seen.set(key, city);
              }
            }
          }
        }
        
        console.log(`üîç Duplicatas removidas (fallback): ${allCities.length} ‚Üí ${uniqueCities.length}`);
        resolve(uniqueCities);
      }
    }, 100);

    setTimeout(() => {
      clearInterval(checkComplete);
      workers.forEach((worker) => worker.terminate());
      reject(new Error("Timeout na coleta de dados"));
    }, 600000);
  });
};
